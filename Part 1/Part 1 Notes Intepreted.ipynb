{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Haar Classifier and Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1: Theories\n",
    "\n",
    "### I. OpenCV\n",
    "OpenCV is the most popular library for computer vision. Originally written in C/C++, it now provides bindings for Python.\n",
    "\n",
    "OpenCV uses machine learning algorithms to search for faces within a picture. For something as complicated as a face, there isn’t one simple test that will tell you if it found a face or not. Instead, there are thousands of small patterns/features that must be matched. The algorithms break the task of identifying the face into thousands of smaller, bite-sized tasks, each of which is easy to solve. These tasks are also called classifiers.\n",
    "\n",
    "For something like a face, you might have 6,000 or more classifiers, all of which must match for a face to be detected (within error limits, of course). But therein lies the problem: For face detection, the algorithm starts at the top left of a picture and moves down across small blocks of data, looking at each block, constantly asking, “Is this a face? … Is this a face? … Is this a face?” Since there are 6,000 or more tests per block, you might have millions of calculations to do, which will grind your computer to a halt.\n",
    "\n",
    "To get around this, OpenCV uses cascades. What’s a cascade? The best answer can be found from the dictionary: A waterfall or series of waterfalls\n",
    "\n",
    "Like a series of waterfalls, the OpenCV cascade breaks the problem of detecting faces into multiple stages. For each block, it does a very rough and quick test. If that passes, it does a slightly more detailed test, and so on. The algorithm may have 30-50 of these stages or cascades, and it will only detect a face if all stages pass. The advantage is that the majority of the pictures will return negative during the first few stages, which means the algorithm won’t waste time testing all 6,000 features on it. Instead of taking hours, face detection can now be done in real time.\n",
    "\n",
    "### II. Cascades in practice\n",
    "Though the theory may sound complicated, in practice it is quite easy. The cascades themselves are just a bunch of XML files that contain OpenCV data used to detect objects. You initialize your code with the cascade you want, and then it does the work for you.\n",
    "\n",
    "Since face detection is such a common case, OpenCV comes with a number of built-in cascades for detecting everything from faces to eyes to hands and legs. There are even cascades for non-human things. For example, if you run a banana shop and want to track people stealing bananas, this guy has built one for that!\n",
    "\n",
    "### III. Classifier\n",
    "A computer program that decides whether an image is a positive image (face image) or negative image (non-face image) is called a classifier. A classifier is trained on hundreds of thousands of face and non-face images to learn how to classify a new image correctly. OpenCV provides us with a pre-trained and ready to be used for face detection classifier:\n",
    "\n",
    "### IV. Haar Classifier\n",
    "\n",
    "Haar Classifier processes images in gray scales, basically because we don't need color information to decide if a picture has a face or not. As these are pre-trained in OpenCV, their learned knowledge files also come bundled with OpenCV opencv/data/.\n",
    "\n",
    "To run a classifier, we need to load the knowledge files first, as if it had no knowledge, just like a newly born baby (stupid babies).\n",
    "\n",
    "Each file starts with the name of the classifier it belongs to. For example, a Haar cascade classifier starts off as haarcascade_frontalface_alt.xml.\n",
    "\n",
    "> more about haar classifier: https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2 : Step by Step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. import packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. locate the files needed\n",
    "> imagePath: path of the image to be processed\n",
    "\n",
    "> cascPath: path of the cascade algorithm to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"./abba.png\"\n",
    "cascPath = \"./haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. create an instance of the classifier, using the 'haarcascade file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. read the image and convert image to gray scale\n",
    ">use the cv2.read(image path as a string) to convert the input image into a numpy array\n",
    "\n",
    ">convert the image into gray scale, which is the prerequisite of the openCV face recognition method\n",
    "\n",
    "<img src=\"imgs/color_to_gray.jpg\" width=\"10%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. call the cv2 method detectMultiScale() \n",
    "\n",
    "> The method will take the image (as a numpy array) as input and output an array that contains rectangles (which contain the faces detected)\n",
    "\n",
    "> Each rectangles are expressed as a four-elemental array ====> (x-coordinate of the left-top corner, y-coordinate of the left-top corner, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>faceCascade.detectMultiScale(image, cascade, storage, scale_factor=1.1, min_neighbors=3, flags=0, min_size=(0, 0)) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Parameters:\t\n",
    "\n",
    ">   cascade – Haar classifier cascade (OpenCV 1.x API only). It can be loaded from XML or YAML file using Load(). When the cascade is not needed anymore, release it using cvReleaseHaarClassifierCascade(&cascade).\n",
    "    \n",
    ">   image – Matrix of the type CV_8U containing an image where objects are detected.\n",
    "    \n",
    ">   objects – Vector of rectangles where each rectangle contains the detected object.\n",
    "    \n",
    ">   scaleFactor – Parameter specifying how much the image size is reduced at each image scale.\n",
    "    \n",
    ">   minNeighbors – Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "    \n",
    ">   flags – Parameter with the same meaning for an old cascade as in the function cvHaarDetectObjects. It is not used for a new cascade.\n",
    "    \n",
    ">   minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "    \n",
    ">   maxSize – Maximum possible object size. Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces in the image\n",
    "#need to study this function when preparing the \n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    #a modification is needed:\n",
    "    #see: [https://stackoverflow.com/questions/36242860/attribute-error-while-using-opencv-for-face-recognition]\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. process the output and show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>cv2.Rectangle(img, pt1, pt2, color, thickness=1, lineType=8, shift=0) → None </font>\n",
    ">Parameters:\n",
    "\n",
    ">img – Image.\n",
    "\n",
    ">pt1 – Vertex of the rectangle.\n",
    "\n",
    ">pt2 – Vertex of the rectangle opposite to pt1 .\n",
    "\n",
    ">rec – Alternative specification of the drawn rectangle.\n",
    "\n",
    ">color – Rectangle color or brightness (grayscale image).\n",
    "\n",
    ">thickness – Thickness of lines that make up the rectangle. Negative values, like CV_FILLED , mean that the function has to draw a filled rectangle.\n",
    "\n",
    ">lineType – Type of the line. See the line() description.\n",
    "\n",
    ">shift – Number of fractional bits in the point coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>cv2.imshow()</font>\n",
    "\n",
    ">Use the function cv2.imshow() to display an image in a window. The window automatically fits to the image size.\n",
    "\n",
    ">First argument is a window name which is a string. second argument is our image. You can create as many windows as you wish, but with different window names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces, with help of the method cv2.rectangle()\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "# waitKey(0) will display the window infinitely until any keypress (it is suitable for image display)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
