{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_path = \"/data/workspace/yeqi/projects/RNN4REC/GRU4REC/Processed Data/min_len_5/X_test.npy\"\n",
    "X_test = np.load(X_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16755, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo a new tester for batch by batch testing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class TestDataGenerator:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        # load data here\n",
    "        # in this fake data generator, the number of training data is simulated to be 100000000\n",
    "        # the second digit in size tuple is the time step in the training data\n",
    "        # here we suppose the time step to be one\n",
    "        self.pro_arr = np.load(self.config.X_test_path)\n",
    "        self.slice_table = self.analyze_data()\n",
    "\n",
    "    def test_data(self, batch_size):\n",
    "        \n",
    "        '''\n",
    "        Input:\n",
    "            1. batch_size as integer\n",
    "            2. self.pro_arr as numpy array, with columns: \n",
    "                [0] userid as integer\n",
    "                [1] pathid as integer\n",
    "                [2] path as numpy array containing itemids as integers\n",
    "                [3] session_length as integer = length_input + length_output = length_input + 1\n",
    "                [4] label (output itemid) as integer\n",
    "        Output:\n",
    "            1. next_batch_userids as numpy array, with size: [batch_size, ] or [batch_size, num_time_step]\n",
    "            2. next_batch_itemids as numpy array, with size: [batch_size, num_time_step]\n",
    "            3. next_batch_y as numpy array, with size: [batch_size, ]\n",
    "        '''\n",
    "        # first step: use sequence to select a session length to generate the next batch\n",
    "        length = 0\n",
    "        start_index = 0\n",
    "        end_index = 0\n",
    "        for i in range(len(self.slice_table)):\n",
    "            if rand >= self.slice_table['start_index'][i] and rand < self.slice_table['end_index'][i]:\n",
    "                length = self.slice_table['length'][i]\n",
    "                start_index = self.slice_table['start_index'][i]\n",
    "                end_index = self.slice_table['end_index'][i]\n",
    "                break\n",
    "        # print(\"generating next batch with session length t_step =\", length)\n",
    "        next_batchids = np.random.randint(start_index, end_index, batch_size)\n",
    "        next_batch_userids = self.pro_arr[next_batchids][:,0]\n",
    "        next_batch_itemids = np.array(self.pro_arr[next_batchids][:,2].tolist())\n",
    "        next_batch_y = self.pro_arr[next_batchids][:,-1]\n",
    "        \n",
    "        yield next_batch_userids, next_batch_itemids, next_batch_y    \n",
    "        \n",
    "    def analyze_data(self):\n",
    "        '''\n",
    "        Input:\n",
    "            1. self.pro_arr as numpy array\n",
    "        Output: \n",
    "            1. the slicing table of pro_arr\n",
    "        '''\n",
    "        df = pd.DataFrame(self.pro_arr)\n",
    "        df.columns = ['userid', 'pathid', 'path', 'length', 'Y']\n",
    "    \n",
    "        print(\"Sample of training data: \")\n",
    "        print(df.head())\n",
    "    \n",
    "        summary = df.groupby('length').count()\n",
    "        summary = pd.DataFrame(summary.drop(columns=['pathid','path']))\n",
    "        summary = summary.reset_index()\n",
    "        summary = summary.drop(['Y'],axis = 1)\n",
    "        summary.columns = ['length', 'count']\n",
    "    \n",
    "        slice_table = summary\n",
    "        slice_table['start_index'] = slice_table['count']\n",
    "        slice_table['end_index'] = slice_table['count']\n",
    "    \n",
    "        # here is the logic for create the start index + end index\n",
    "        for i in range(1, len(slice_table)):\n",
    "            slice_table['end_index'][i] = slice_table['end_index'][i-1] + slice_table['count'][i]\n",
    "    \n",
    "        for i in range(1, len(slice_table)):\n",
    "            slice_table['start_index'][i] = slice_table['end_index'][i-1]\n",
    "    \n",
    "        slice_table['start_index'][0] = 0\n",
    "        print(\"Here is the slicing table of the data: \")\n",
    "        print(slice_table)\n",
    "        \n",
    "        return slice_table\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(config_dict):\n",
    "    config = edict(config_dict)\n",
    "    config.summary_dir = os.path.join(\"../experiments\", config.exp_name, \"summary/\")\n",
    "    config.checkpoint_dir = os.path.join(\"../experiments\", config.exp_name, \"checkpoint/\")\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "  \"exp_name\": \"GRU\",\n",
    "  \"num_epochs\": 100,\n",
    "  \"num_iter_per_epoch\": 100,\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"batch_size\": 256,\n",
    "\n",
    "  \"max_to_keep\": 5,\n",
    "  \n",
    "  \"num_steps\": 2,\n",
    "  \"item_emb_size\": 150,\n",
    "  \"user_emb_size\": 150,\n",
    "  \"w2v_size\": 1000,\n",
    "  \"num_item\": 298000,\n",
    "  \"num_user\": 25400,\n",
    "  \"num_layers\": 1,\n",
    "  \"dropout\": 0.0,\n",
    "  \"num_units_4emb\": 300,\n",
    "  \n",
    "\n",
    "  \"X_train_path\": \"/data/workspace/yeqi/projects/RNN4REC/GRU4REC/Processed Data/min_len_5/X_train.npy\",\n",
    "  \"X_test_path\": \"/data/workspace/yeqi/projects/RNN4REC/GRU4REC/Processed Data/min_len_5/X_test.npy\"\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = process_config(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training data: \n",
      "  userid pathid                              path length       Y\n",
      "0  11005      1     [32814, 151616, 30251, 20452]      5   32046\n",
      "1   7023     38   [164225, 85683, 123109, 146134]      5   98443\n",
      "2   4288     43  [125822, 126082, 172605, 220459]      5  207481\n",
      "3  23598     34   [69876, 102562, 100926, 149212]      5  175247\n",
      "4  22643     49   [190805, 206507, 166357, 98085]      5   53280\n",
      "Here is the slicing table of the data: \n",
      "   length  count  start_index  end_index\n",
      "0       5   5580            0       5580\n",
      "1       6   3244         5580       8824\n",
      "2      10   5035         8824      13859\n",
      "3      20   2294        13859      16153\n",
      "4      50    534        16153      16687\n",
      "5     100     68        16687      16755\n"
     ]
    }
   ],
   "source": [
    "tdg = TestDataGenerator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
