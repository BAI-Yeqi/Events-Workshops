{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Create a user log file with the camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import logging as log\n",
    "import datetime as dt\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. assign the path of the knowledge file (as a string value) to a variable called 'cascPath'\n",
    "\n",
    "> string value: \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create an instance of the CascadeClassifier, assign it to a variable called 'faceCascade'\n",
    "\n",
    "> to create an instance of the classifier, call the method cv2.CascadeClassifier(), where 'cascPath' is the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a file object named 'f' , with file name 'user numbers log.txt' and mode 'w+'\n",
    "\n",
    "\n",
    "<img src='imgs/fileio.jpg', width='100%'>\n",
    "\n",
    "reference: https://docs.python.org/3/tutorial/inputoutput.html\n",
    "> 'w+'\n",
    "\n",
    "> Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. create a video Capture object and name it as video_capture\n",
    "\n",
    ">To capture a video, you need to create a VideoCapture object. \n",
    "\n",
    ">Find your answer in the following webpage: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. initialize an integer called 'user_no_prev' with value 0 and a datetime object called 'time_prev'\n",
    "\n",
    "> 'time_prev' will save the current local data and time (the exact time ogf this moment)\n",
    "\n",
    "> find your answer in the following page: https://docs.python.org/3/library/datetime.html#datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the values above will be compared with real-time values in the loop, so that we can tell if no. of people that appears in the camera has changed, in every loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Now we have prepared all the objects/variables needed for the \"user_log_maker\", the next thing we will do is to build a loop which will:\n",
    "\n",
    "\n",
    "<font color = 'purple'>\n",
    "<p>\n",
    "<br>\n",
    "(a) repeatedly check the availability of the camera;\n",
    "<br><br>\n",
    "(b) repeatedly read image from the camera video stream, detect faces in the stream;\n",
    "<br><br>\n",
    "(c) repeatedly figure out whether the number of faces appeared in the camera has changed, if the answer is 'yes', record the picture and mark it down in the log file;\n",
    "<br><br>\n",
    "(d) using the data returned by (b), repeatedly (or in another word, continously) display the image (which will form a video stream on your screen) with rectangles that highlight the faces.\n",
    "<br>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will build the loop in a modular way, let us now prepares the components needed for the loop:\n",
    "\n",
    "(a) repeatedly check the availability of the camera ------>  function check_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_camera():\n",
    "     if not video_capture.isOpened():\n",
    "        print('Unable to load camera.')\n",
    "        sleep(5)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) repeatedly read image from the camera video stream, detect faces in the stream\n",
    "\n",
    "> Call the 'read()' method of your video_capture object, store the outputs as 'ret' (which indicates whether the image reading is successful), 'frame' (the numpy array version of the video frame)\n",
    "\n",
    "> Convert 'frame' into Gray Scale, and store it as 'gray'\n",
    "\n",
    "> Call the 'detectMultiscale()' method\n",
    "\n",
    "<font color = 'pink'> Hint: do refer to the Part 1 step by step tutorial </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_faces():\n",
    "    \n",
    "    ### Start your coding here:\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### End of your coding\n",
    "    \n",
    "    return faces,frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) using the data returned by (b), repeatedly (or in another word, continously) display the image (which will form a video stream on your screen) with rectangles that highlight the faces. \n",
    "\n",
    ">   1. draw the rectangle\n",
    ">   2. display the image\n",
    "\n",
    "<font color = 'pink'> Hint: do refer to the Part 1 step by step tutorial </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_player():\n",
    "    # Draw a rectangle around the faces\n",
    "       \n",
    "        \n",
    "        \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) repeatedly figure out whether the number of faces appeared in the camera has changed, if the answer is 'yes', record the picture and mark it down in the log file \n",
    "\n",
    "> 1 call the 'check_camera()' function\n",
    "\n",
    "> 2 call the 'detect_faces()' function, assign the outputs to teo variables called 'faces' and 'frame'\n",
    "\n",
    "\n",
    "<font size = 4> Now, complete the code below </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    ### start your code here (about 2 lines of code)   \n",
    " \n",
    "\n",
    "\n",
    "    ### end of your code\n",
    "\n",
    "    \n",
    "        \n",
    "    ### BYQ helped you code this part already\n",
    "    ### when no. of users appeared in the camera changes, record into the log file and take a picture   \n",
    "    user_no = len(faces)\n",
    "    if user_no != user_no_prev:\n",
    "        f.write(\"time duration: from \" + str(time_prev) + \" to \" + str(dt.datetime.now()) + \"\\n\")\n",
    "        f.write(\"      there are %d users  \\n\" % user_no)\n",
    "        if user_no_prev == 0:\n",
    "            log_frame = frame\n",
    "        if user_no_prev > 0:\n",
    "            photo_name = \"from_\" + str(time_prev.strftime(\"%H_%M_%S\")) + \"_to_\" + str(dt.datetime.now().strftime(\"%H_%M_%S\"))\n",
    "            cv2.imwrite(photo_name + '.png',log_frame)\n",
    "            \n",
    "    user_no_prev = user_no    \n",
    "    time_prev = dt.datetime.now()  \n",
    "    ### BYQ peace out\n",
    "\n",
    "    \n",
    "    \n",
    "    ### start your code here ( 1 line )\n",
    "    ### display the video, with the funtion we built\n",
    "    \n",
    "\n",
    "    \n",
    "    ### end of your code\n",
    "    \n",
    "    \n",
    "     \n",
    "    # press \"q\" to quit app\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red ' size = 4> Type \"Q\" to quit the loop </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Close your file object, release your camera and destroy the video player window\n",
    " \n",
    "\n",
    "    > ### Hint:\n",
    "    \"name of the file object\".close()\n",
    "    \"name of the video capture object\".release()\n",
    "    \"name of the computer vision package we imported\".destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### start your code here (about three lines of code)\n",
    " \n",
    "    \n",
    "    \n",
    "### end of your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
