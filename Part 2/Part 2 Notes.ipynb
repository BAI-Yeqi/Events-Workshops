{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Create a user log file with the camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import logging as log\n",
    "import datetime as dt\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. assign the path of the knowledge file (as a string value) to a variable called 'cascPath'\n",
    "\n",
    "> string value: \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cascPath = \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create an instance of the CascadeClassifier, assign it to a variable called 'faceCascade'\n",
    "\n",
    "> to create an instance of the classifier, call the method cv2.CascadeClassifier(), where 'cascPath' is the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a file object named 'f' , with file name 'user numbers log.txt' and mode 'w+'\n",
    "\n",
    "\n",
    "<img src='imgs/fileio.jpg', width='100%'>\n",
    "\n",
    "reference: https://docs.python.org/3/tutorial/inputoutput.html\n",
    "> 'w+'\n",
    "\n",
    "> Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f= open(\"user numbers log.txt\",\"w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. create a video Capture object and name it as video_capture\n",
    "\n",
    ">To capture a video, you need to create a VideoCapture object. \n",
    "\n",
    ">Find your answer in the following webpage: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. initialize an integer called 'user_no_prev' with value 0 and a datetime object called 'time_prev'\n",
    "\n",
    "> 'time_prev' will save the current local data and time (the exact time ogf this moment)\n",
    "\n",
    "> find your answer in the following page: https://docs.python.org/3/library/datetime.html#datetime.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_no_prev = 0\n",
    "time_prev = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the values above will be compared with real-time values in the loop, so that we can tell if no. of people that appears in the camera has changed, in every loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Now we have prepared all the objects/variables needed for the \"user_log_maker\", the next thing we will do is to build a loop which will:\n",
    "\n",
    "\n",
    "<font color = 'purple'>\n",
    "<p>\n",
    "<br>\n",
    "(a) repeatedly check the availability of the camera;\n",
    "<br><br>\n",
    "(b) repeatedly read image from the camera video stream, detect faces in the stream;\n",
    "<br><br>\n",
    "(c) repeatedly figure out whether the number of faces appeared in the camera has changed, if the answer is 'yes', record the picture and mark it down in the log file;\n",
    "<br><br>\n",
    "(d) using the data returned by (b), repeatedly (or in another word, continously) display the image (which will form a video stream on your screen) with rectangles that highlight the faces.\n",
    "<br>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will build the loop in a modular way, let us now prepares the components needed for the loop:\n",
    "\n",
    "(a) repeatedly check the availability of the camera ------>  function check_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_camera():\n",
    "     if not video_capture.isOpened():\n",
    "        print('Unable to load camera.')\n",
    "        sleep(5)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) repeatedly read image from the camera video stream, detect faces in the stream\n",
    "\n",
    "> Call the 'read' method of your video_capture object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_faces():\n",
    "    \n",
    "    ### Start your coding here:\n",
    "    \n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    \n",
    "    ### End of your coding\n",
    "    \n",
    "    return faces,frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) using the data returned by (b), repeatedly (or in another word, continously) display the image (which will form a video stream on your screen) with rectangles that highlight the faces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_player():\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) repeatedly figure out whether the number of faces appeared in the camera has changed, if the answer is 'yes', record the picture and mark it down in the log file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    check_camera()\n",
    "\n",
    "    faces,frame = detect_faces()\n",
    "\n",
    "    ###added by BYQ\n",
    "    user_no = len(faces)\n",
    "    if user_no != user_no_prev:\n",
    "        f.write(\"time duration: from \" + str(time_prev) + \" to \" + str(dt.datetime.now()) + \"\\n\")\n",
    "        f.write(\"      there are %d users  \\n\" % user_no)\n",
    "        if user_no_prev == 0:\n",
    "            log_frame = frame\n",
    "        if user_no_prev > 0:\n",
    "            photo_name = \"from_\" + str(time_prev.strftime(\"%H_%M_%S\")) + \"_to_\" + str(dt.datetime.now().strftime(\"%H_%M_%S\"))\n",
    "            cv2.imwrite(photo_name + '.png',log_frame)\n",
    "            \n",
    "    user_no_prev = user_no    \n",
    "    time_prev = dt.datetime.now()\n",
    "    ###BYQ peace out\n",
    "\n",
    "    video_player()\n",
    "    #press \"q\" to quit app\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "f.close()\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
